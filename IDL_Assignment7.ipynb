{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDL_Assignment7.ipynb",
      "provenance": [],
      "mount_file_id": "1eEecUK3ztFgPOmlZG7n0fqvDtgGu3XAw",
      "authorship_tag": "ABX9TyN0Xha4q0jC8KQfQQEonDEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackCurrantDS/DeepLearning/blob/main/IDL_Assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zeNSxZaJvqk"
      },
      "source": [
        "References-\r\n",
        "\r\n",
        "https://www.tensorflow.org/tutorials/text/transformer\r\n",
        "\r\n",
        "https://medium.com/datadriveninvestor/attention-mechanism-encoder-and-decoder-f95d7d7005c8\r\n",
        "\r\n",
        "https://trungtran.io/2019/03/29/neural-machine-translation-with-attention-mechanism/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSuPRMKkA-yR"
      },
      "source": [
        "Translation using Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebuN7cJlAa-e"
      },
      "source": [
        "#imports\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import unicodedata\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import io\r\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-P7z308C1qm"
      },
      "source": [
        "# Converts the unicode file to ascii\r\n",
        "def unicode_to_ascii(s):\r\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\r\n",
        "      if unicodedata.category(c) != 'Mn')\r\n",
        "\r\n",
        "\r\n",
        "def preprocess_sentence(w):\r\n",
        "  w = unicode_to_ascii(w.lower().strip())\r\n",
        "\r\n",
        "  # creating a space between a word and the punctuation following it\r\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\r\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\r\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\r\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\r\n",
        "\r\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\r\n",
        "  #w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\r\n",
        "\r\n",
        "  w = w.rstrip().strip()\r\n",
        "\r\n",
        "  # adding a start and an end token to the sentence\r\n",
        "  # so that the model know when to start and stop predicting.\r\n",
        "  w = '<start> ' + w + ' <end>'\r\n",
        "  return w"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj1ZYislC9e3",
        "outputId": "600f285e-a804-4174-f9ae-0c499c31ec26"
      },
      "source": [
        "en_sentence = u\"He saw a pretty girl.\"\r\n",
        "hin_sentence = u\"उसने एक सुंदर लड़की को देखा।\"\r\n",
        "print(preprocess_sentence(en_sentence))\r\n",
        "print(preprocess_sentence(hin_sentence))\r\n",
        "print(preprocess_sentence(hin_sentence).encode('utf-8'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> he saw a pretty girl . <end>\n",
            "<start> उसन एक सदर लडकी को दखा। <end>\n",
            "b'<start> \\xe0\\xa4\\x89\\xe0\\xa4\\xb8\\xe0\\xa4\\xa8 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xb8\\xe0\\xa4\\xa6\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb2\\xe0\\xa4\\xa1\\xe0\\xa4\\x95\\xe0\\xa5\\x80 \\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xa6\\xe0\\xa4\\x96\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4 <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRYzC2U6FS-1"
      },
      "source": [
        "# 1. Remove the accents\r\n",
        "# 2. Clean the sentences\r\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\r\n",
        "def create_dataset(path, num_examples):\r\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\r\n",
        "  \r\n",
        "\r\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:-1]]  for l in lines[:num_examples]]\r\n",
        "\r\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziObiWTAFV91",
        "outputId": "eee4c9f1-db49-46d5-ede6-462ce94c5bfc"
      },
      "source": [
        "path_to_file = \"/content/hin.txt\"\r\n",
        "en, hin = create_dataset(\"hin.txt\", None)\r\n",
        "print(en[-1])\r\n",
        "print(hin[-1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> when i was a kid , touching bugs didn't bother me a bit . now i can hardly stand looking at pictures of them . <end>\n",
            "<start> जब म बचचा था , मझ कीडो को छन स कोई परशानी नही होती थी , पर अब म उनकी तसवीर दखना भी बरदाशत नही कर सकता। <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTu3cDeKGu9M"
      },
      "source": [
        "def tokenize(lang):\r\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\r\n",
        "      filters='')\r\n",
        "  lang_tokenizer.fit_on_texts(lang)\r\n",
        "\r\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\r\n",
        "\r\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\r\n",
        "                                                         padding='post')\r\n",
        "\r\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9V7PPIZGxU8"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\r\n",
        "  # creating cleaned input, output pairs\r\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\r\n",
        "\r\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\r\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\r\n",
        "\r\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy42g7bwGzxN"
      },
      "source": [
        "# Try experimenting with the size of that dataset\r\n",
        "num_examples = 30000\r\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\r\n",
        "\r\n",
        "# Calculate max_length of the target tensors\r\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcDxxIhoG38M",
        "outputId": "436a2fb3-a935-44e4-da40-592b31622d63"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\r\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\r\n",
        "\r\n",
        "# Show length\r\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2338 2338 585 585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHU5mAdrG5_c"
      },
      "source": [
        "def convert(lang, tensor):\r\n",
        "  for t in tensor:\r\n",
        "    if t!=0:\r\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRKjGKrvG7x9",
        "outputId": "ec3b91d9-3487-4520-d226-8560bd7150e4"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\r\n",
        "convert(inp_lang, input_tensor_train[0])\r\n",
        "print ()\r\n",
        "print (\"Target Language; index to word mapping\")\r\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "32 ----> हम\n",
            "596 ----> आखिरकार\n",
            "565 ----> झील\n",
            "77 ----> तक\n",
            "431 ----> पहच\n",
            "164 ----> गए।\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "33 ----> at\n",
            "121 ----> last\n",
            "22 ----> ,\n",
            "29 ----> we\n",
            "141 ----> got\n",
            "6 ----> to\n",
            "4 ----> the\n",
            "614 ----> lake\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRRu7YjOHBQM"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\r\n",
        "BATCH_SIZE = 64\r\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\r\n",
        "embedding_dim = 256\r\n",
        "units = 1024\r\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\r\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\r\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f53HSug9HEeE",
        "outputId": "07bb535f-f34e-4160-e260-ef7e22dfcd21"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\r\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 29]), TensorShape([64, 27]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JywVyKxfHIPk"
      },
      "source": [
        "class Encoder(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.enc_units = enc_units\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "  def call(self, x, hidden):\r\n",
        "    x = self.embedding(x)\r\n",
        "    output, state = self.gru(x, initial_state = hidden)\r\n",
        "    return output, state\r\n",
        "\r\n",
        "  def initialize_hidden_state(self):\r\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWX1mqAJHKUk",
        "outputId": "23e4e20a-75ed-49c6-f664-147831f210b8"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "# sample input\r\n",
        "sample_hidden = encoder.initialize_hidden_state()\r\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\r\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\r\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 29, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhIPtAbXHOhU"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, units):\r\n",
        "    super(BahdanauAttention, self).__init__()\r\n",
        "    self.W1 = tf.keras.layers.Dense(units)\r\n",
        "    self.W2 = tf.keras.layers.Dense(units)\r\n",
        "    self.V = tf.keras.layers.Dense(1)\r\n",
        "\r\n",
        "  def call(self, query, values):\r\n",
        "    # query hidden state shape == (batch_size, hidden size)\r\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\r\n",
        "    # values shape == (batch_size, max_len, hidden size)\r\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\r\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\r\n",
        "\r\n",
        "    # score shape == (batch_size, max_length, 1)\r\n",
        "    # we get 1 at the last axis because we are applying score to self.V\r\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\r\n",
        "    score = self.V(tf.nn.tanh(\r\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\r\n",
        "\r\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\r\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\r\n",
        "\r\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\r\n",
        "    context_vector = attention_weights * values\r\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\r\n",
        "\r\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-rIIwPMHQGc",
        "outputId": "7acb6a70-7bb8-4359-93e6-0f314695918a"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\r\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\r\n",
        "\r\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\r\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 29, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JOfkA7jHSey"
      },
      "source": [
        "class Decoder(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.dec_units = dec_units\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    # used for attention\r\n",
        "    self.attention = BahdanauAttention(self.dec_units)\r\n",
        "\r\n",
        "  def call(self, x, hidden, enc_output):\r\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\r\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\r\n",
        "\r\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n",
        "    x = self.embedding(x)\r\n",
        "\r\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n",
        "\r\n",
        "    # passing the concatenated vector to the GRU\r\n",
        "    output, state = self.gru(x)\r\n",
        "\r\n",
        "    # output shape == (batch_size * 1, hidden_size)\r\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\r\n",
        "\r\n",
        "    # output shape == (batch_size, vocab)\r\n",
        "    x = self.fc(output)\r\n",
        "\r\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq4DkZkLHUXr",
        "outputId": "010f4aa0-e70b-4c34-856e-a1e5ea7b9890"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\r\n",
        "                                      sample_hidden, sample_output)\r\n",
        "\r\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 2438)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc87bdMEHXSr"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "    from_logits=True, reduction='none')\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n",
        "  loss_ = loss_object(real, pred)\r\n",
        "\r\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
        "  loss_ *= mask\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReOKfQunHZDL"
      },
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/chkpoint_folder'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCXyfWolHj3S"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(inp, targ, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n",
        "\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "\r\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\r\n",
        "\r\n",
        "    # Teacher forcing - feeding the target as the next input\r\n",
        "    for t in range(1, targ.shape[1]):\r\n",
        "      # passing enc_output to the decoder\r\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n",
        "\r\n",
        "      loss += loss_function(targ[:, t], predictions)\r\n",
        "\r\n",
        "      # using teacher forcing\r\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\r\n",
        "\r\n",
        "  batch_loss = (loss / int(targ.shape[1]))\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "\r\n",
        "  gradients = tape.gradient(loss, variables)\r\n",
        "\r\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\r\n",
        "\r\n",
        "  return batch_loss"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ1DcHhMHlgr",
        "outputId": "971e6732-2cf7-496d-b8df-0abee174461b"
      },
      "source": [
        "EPOCHS = 10\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start = time.time()\r\n",
        "\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\r\n",
        "    total_loss += batch_loss\r\n",
        "\r\n",
        "    if batch % 100 == 0:\r\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                                   batch,\r\n",
        "                                                   batch_loss.numpy()))\r\n",
        "  # saving (checkpoint) the model every 2 epochs\r\n",
        "  if (epoch + 1) % 2 == 0:\r\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                      total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.3787\n",
            "Epoch 1 Loss 1.7961\n",
            "Time taken for 1 epoch 33.55572557449341 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4568\n",
            "Epoch 2 Loss 1.5018\n",
            "Time taken for 1 epoch 8.422091245651245 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.4676\n",
            "Epoch 3 Loss 1.3956\n",
            "Time taken for 1 epoch 7.13768744468689 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.3117\n",
            "Epoch 4 Loss 1.3194\n",
            "Time taken for 1 epoch 8.40192699432373 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.2021\n",
            "Epoch 5 Loss 1.2436\n",
            "Time taken for 1 epoch 7.251919269561768 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.2088\n",
            "Epoch 6 Loss 1.1653\n",
            "Time taken for 1 epoch 8.493279933929443 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.0523\n",
            "Epoch 7 Loss 1.0926\n",
            "Time taken for 1 epoch 7.2884132862091064 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.0337\n",
            "Epoch 8 Loss 1.0307\n",
            "Time taken for 1 epoch 8.61251974105835 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.9508\n",
            "Epoch 9 Loss 0.9708\n",
            "Time taken for 1 epoch 7.381201982498169 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.0073\n",
            "Epoch 10 Loss 0.9114\n",
            "Time taken for 1 epoch 8.670194625854492 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bSZfM6cHwR7"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\r\n",
        "\r\n",
        "  sentence = preprocess_sentence(sentence)\r\n",
        "\r\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                         maxlen=max_length_inp,\r\n",
        "                                                         padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "\r\n",
        "  result = ''\r\n",
        "\r\n",
        "  hidden = [tf.zeros((1, units))]\r\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "\r\n",
        "  dec_hidden = enc_hidden\r\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\r\n",
        "\r\n",
        "  for t in range(max_length_targ):\r\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "\r\n",
        "    # storing the attention weights to plot later on\r\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "    attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "\r\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\r\n",
        "\r\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\r\n",
        "      return result, sentence, attention_plot\r\n",
        "\r\n",
        "    # the predicted ID is fed back into the model\r\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76a21wffHyET"
      },
      "source": [
        "# function for plotting the attention weights\r\n",
        "def plot_attention(attention, sentence, predicted_sentence):\r\n",
        "  fig = plt.figure(figsize=(10,10))\r\n",
        "  ax = fig.add_subplot(1, 1, 1)\r\n",
        "  ax.matshow(attention, cmap='viridis',clim=[0,1])\r\n",
        "\r\n",
        "  fontdict = {'fontsize': 14}\r\n",
        "\r\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\r\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\r\n",
        "\r\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqcW6KcUHykb"
      },
      "source": [
        "def translate(sentence):\r\n",
        "  result, sentence, attention_plot = evaluate(sentence)\r\n",
        "\r\n",
        "  print('Input: %s' % (sentence))\r\n",
        "  print('Predicted translation: {}'.format(result))\r\n",
        "\r\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\r\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p9zmqCSH1Cr",
        "outputId": "b65b496f-7266-4023-b9f9-f6f8e1b37088"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb8aaa4c438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZV3onM5pH297",
        "outputId": "59348539-c85d-4618-9855-398ee38e1000"
      },
      "source": [
        "translate(u'बहुत बढ़िया!')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> बहत बढिया ! <end>\n",
            "Predicted translation: jump . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2338 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2338 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "89IHNlcMH5JM",
        "outputId": "f258b581-0fd3-494d-89aa-57732d4925d1"
      },
      "source": [
        "translate(u'कृपया जाईये।')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input: <start> कपया जाईय। <end>\n",
            "Predicted translation: please have to go home . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU6LBqWwOj_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b010d2-44e9-4555-d9b9-6155905eca7f"
      },
      "source": [
        "print(\"Done til here\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done til here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU6y5q17-inX"
      },
      "source": [
        "Luong Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjW6AU7L-pvZ"
      },
      "source": [
        "class LuongAttention(tf.keras.layers.Layer):\r\n",
        "  def __init__(self,units, max_len_inp):\r\n",
        "    super(LuongAttention,self).__init__()\r\n",
        "    self.W = tf.keras.layers.Dense(units)\r\n",
        "    self.V = tf.keras.layers.Dense(max_length_inp)\r\n",
        "  \r\n",
        "  def call(self, query, values):\r\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\r\n",
        "\r\n",
        "    score = tf.matmul(self.W(query_with_time_axis), values, transpose_b=True)   \r\n",
        "    score = tf.transpose(score, [0, 2, 1])\r\n",
        " \r\n",
        "    attention_weights = tf.nn.softmax(score,axis = 1)\r\n",
        " \r\n",
        "    context = attention_weights*values\r\n",
        "  \r\n",
        "    context = tf.reduce_sum(context, axis=1)\r\n",
        "  \r\n",
        "    return context, attention_weights"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTLdNFbZ_gWn",
        "outputId": "3f9e1459-2500-4b0c-dda1-eb68c811d1c8"
      },
      "source": [
        "attention_layer = LuongAttention(1024,max_length_inp)\r\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\r\n",
        "\r\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\r\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 29, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynn2IGQQ4uPy"
      },
      "source": [
        "class Decoder(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.dec_units = dec_units\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "    \r\n",
        "    self.max_input_length = max_length_inp\r\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    # used for attention\r\n",
        "    self.attention = LuongAttention(self.dec_units, self.max_input_length)\r\n",
        "\r\n",
        "  def call(self, x, hidden, enc_output):\r\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\r\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\r\n",
        "\r\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n",
        "    x = self.embedding(x)\r\n",
        "\r\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n",
        "\r\n",
        "    # passing the concatenated vector to the GRU\r\n",
        "    output, state = self.gru(x)\r\n",
        "\r\n",
        "    # output shape == (batch_size * 1, hidden_size)\r\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\r\n",
        "\r\n",
        "    # output shape == (batch_size, vocab)\r\n",
        "    x = self.fc(output)\r\n",
        "\r\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUaLGfFp5NEK",
        "outputId": "8e5942ad-972e-4d17-c189-157e0ea4df7e"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\r\n",
        "                                      sample_hidden, sample_output)\r\n",
        "\r\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 2438)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipBVh8P067xP"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "    from_logits=True, reduction='none')\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n",
        "  loss_ = loss_object(real, pred)\r\n",
        "\r\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
        "  loss_ *= mask\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF78G8eN69lT"
      },
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/chkpoint_folder/luong'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk7VfYP07GLQ"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(inp, targ, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n",
        "\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "\r\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\r\n",
        "\r\n",
        "    # Teacher forcing - feeding the target as the next input\r\n",
        "    for t in range(1, targ.shape[1]):\r\n",
        "      # passing enc_output to the decoder\r\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n",
        "\r\n",
        "      loss += loss_function(targ[:, t], predictions)\r\n",
        "\r\n",
        "      # using teacher forcing\r\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\r\n",
        "\r\n",
        "  batch_loss = (loss / int(targ.shape[1]))\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "\r\n",
        "  gradients = tape.gradient(loss, variables)\r\n",
        "\r\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\r\n",
        "\r\n",
        "  return batch_loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_KqKCTI7H2I",
        "outputId": "a1b3f1f5-a05f-488f-84eb-95375ed44f2f"
      },
      "source": [
        "EPOCHS = 10\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start = time.time()\r\n",
        "\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\r\n",
        "    total_loss += batch_loss\r\n",
        "\r\n",
        "    if batch % 100 == 0:\r\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                                   batch,\r\n",
        "                                                   batch_loss.numpy()))\r\n",
        "  # saving (checkpoint) the model every 2 epochs\r\n",
        "  if (epoch + 1) % 2 == 0:\r\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                      total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.4141\n",
            "Epoch 1 Loss 1.7210\n",
            "Time taken for 1 epoch 30.159037113189697 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4113\n",
            "Epoch 2 Loss 1.4212\n",
            "Time taken for 1 epoch 5.852864027023315 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.2351\n",
            "Epoch 3 Loss 1.2759\n",
            "Time taken for 1 epoch 4.813340663909912 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.2855\n",
            "Epoch 4 Loss 1.1707\n",
            "Time taken for 1 epoch 5.889228582382202 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.0774\n",
            "Epoch 5 Loss 1.0794\n",
            "Time taken for 1 epoch 4.879671573638916 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.0410\n",
            "Epoch 6 Loss 1.0134\n",
            "Time taken for 1 epoch 6.067532300949097 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.9925\n",
            "Epoch 7 Loss 0.9566\n",
            "Time taken for 1 epoch 4.898154020309448 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.9343\n",
            "Epoch 8 Loss 0.8864\n",
            "Time taken for 1 epoch 5.956777334213257 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.7173\n",
            "Epoch 9 Loss 0.8313\n",
            "Time taken for 1 epoch 4.917116403579712 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.9247\n",
            "Epoch 10 Loss 0.8310\n",
            "Time taken for 1 epoch 6.188989162445068 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mg8Frdi7KUH"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\r\n",
        "\r\n",
        "  sentence = preprocess_sentence(sentence)\r\n",
        "\r\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                         maxlen=max_length_inp,\r\n",
        "                                                         padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "\r\n",
        "  result = ''\r\n",
        "\r\n",
        "  hidden = [tf.zeros((1, units))]\r\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "\r\n",
        "  dec_hidden = enc_hidden\r\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\r\n",
        "\r\n",
        "  for t in range(max_length_targ):\r\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "\r\n",
        "    # storing the attention weights to plot later on\r\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "    attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "\r\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\r\n",
        "\r\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\r\n",
        "      return result, sentence, attention_plot\r\n",
        "\r\n",
        "    # the predicted ID is fed back into the model\r\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkVLTNGG7fkO"
      },
      "source": [
        "# function for plotting the attention weights\r\n",
        "def plot_attention(attention, sentence, predicted_sentence):\r\n",
        "  fig = plt.figure(figsize=(10,10))\r\n",
        "  ax = fig.add_subplot(1, 1, 1)\r\n",
        "  ax.matshow(attention, cmap='viridis',clim=[0,1])\r\n",
        "\r\n",
        "  fontdict = {'fontsize': 14}\r\n",
        "\r\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\r\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\r\n",
        "\r\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8qbiA_n7hL_"
      },
      "source": [
        "def translate(sentence):\r\n",
        "  result, sentence, attention_plot = evaluate(sentence)\r\n",
        "\r\n",
        "  print('Input: %s' % (sentence))\r\n",
        "  print('Predicted translation: {}'.format(result))\r\n",
        "\r\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\r\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Uex1eT7imn",
        "outputId": "cf3d3e97-d409-423d-c08e-346ca110fe33"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb8462529b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lLo1Qdaz7pKd",
        "outputId": "10393143-a54d-422a-e54a-241c3251660e"
      },
      "source": [
        "translate(u'बहुत बढ़िया!')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> बहत बढिया ! <end>\n",
            "Predicted translation: please ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2338 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2338 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAIPCAYAAAAVTijzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZsUlEQVR4nO3de5StB1nf8d9DEhJIuAgiAZRrQVBuhgMBQRoaVlPQdi0sC+R+sUZBRMtCWqUIliIFAcHCKkS5iIBCUYuKolwLIhggqETkEg1guKNoEi5JgKd/7H1gGHLgzMmZec888/msdVZm9vvuPc/kPVn7m/e2q7sDAMDudrmlBwAA4LITdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4i6oarqxlX1hqq6xdKzAADbT9TN9aAkpyR56MJzAAA7oLp76Rk4zKqqknwoyWuT/Psk1+7uLy86FACwreypm+mUJFdK8sgkX0py90WnAQC2naib6UFJXtndn0/y2+vvAYDBHH4dpqqOT/LxJD/Y3W+pqlsneVuSa3X3Py87HQCwXeypm+c/JvlMd78lSbr7L5N8MMmPLDoVAGyzqjq+qh5YVVdZepYliLp5HpDkJZsee0mSB+/8KACwo+6V5IVZvRfuOQ6/DlJV35Xk3CQ36+4Pbnj8O7O6GvZ7uvsDC40HANuqqt6Y5JpJPt/d+5aeZ6eJOgBg16uq6yf5QJLbJXl7kpO6+71LzrTTHH4dpqquu75P3aUu2+l5AGCHPCDJW9bnkv9R9uCdH0TdPOcmucbmB6vq6utlADDRA5P85vrrlya534F2ckzl8OswVfWVJNfs7k9vevx6Sd7b3ccvMxnMVFW3S3LcFp5yQXe/e7vmgb2oqr4/yZ8mObG7L6yqyyf5RJJ7d/drl51u5xy99AAcHlX1q+svO8mTq+rzGxYfldU5Bn+544PBfC9K8n+THOwegVOz+u8ROHwelORV3X1hknT3xVX1iqzu/CDq2HVusf5nJblZkos3LLs4yVlJnrbTQ8EecFF3//zBrlxV79jOYWCvqapjs7qVyX02LXpJkj+pqhP2x950om6I7r7L+tyBVyR5aHdfsPRMsEds9RwW57zA4XWlJD+d1eHXr+ruP6uqH09yQpI9EXXOqRukqo5K8sUkt9prl3HDUqrqrO4+aQvrn9ndDr8Ch52rXwfp7i8n+XCSyy89CwCwsxx+neeJSf5nVd2/uz+z9DDAN9hTt1iA7VJV5+YgT2fo7htu8zhHBFE3z6OT3CDJR6vqvCSf27iwu2+5yFQw14er6m1bWP892zYJ7C3P3vD1CUkeleTMJPv/e7xDVleaP32H51qMc+qGqarHf7Pl3f2LOzULAOyEqnpRkg909y9tevznknxvd99/kcF2mKgDuAyq6k3Z2nmsn+zue2zTOLAnVdX5WX3W6zmbHv9XSc7q7isvM9nOcvgV4LK5Snd/38Gu7D51sC0+l+SUJOdsevyUJJ/fvPJUom6Y9UejPDarmzBeN8kxG5d391FLzAWDuU8dLO9XkjynqvYlefv6sdtn9UkTT1hqqJ0m6uZ5YpJ7J3lyVn/JfzbJ9ZP8SJLHLTcWAGyP7n5qVX0oq5sQ32v98N8meVB3v2KxwXaYc+qGWV/i/bDufk1VXZDk1t39d1X1sCSndvc9Fx4RRnHzYeBIYU/dPNdMsv/TJC5MctX1169J8pRFJgKAHVJVV82mD1fo7n9aaJwdJerm+UiSa6//eU6S05K8K6v79XxhwblgquOr6gUHuW7FzYfhsKuq6yV5blYXRmy8Gr2yOo91T5xPLurm+b0kp2Z1ouizkvxWVf1Ykusk+eUlB4Oh7pZNFyR9C/7nCg6/F2Z1ZOpHk3wse/SCJOfUDVdVJye5Y1Y3ZfzDpefhG1XVI/O1w+QH42Pd/evbNQ9bY/vB8qrqwiS37+6zl55lSaJumKq6c5I/7+4vbXr86CTf391vXmYyDqSq/jqrj3c72MNyT3Si/ZHD9oPlVdV7kjy4u9+19CxLEnXDVNWXk1yruz+16fGrJ/mU+9Qdearq3Vu9eW1333Y7Z+Lg2X6wvKr6N0n+a5KHb/5Uib3EOXXz7D8pdLOrZ3XHbY48bl67u9l+sLxXJTk2yfur6qIkX3e0yseEsatU1e+vv+wkL1n/pd7vqCQ3T/LnOz4YAGy/Ryw9wJFA1M3xj+t/VpLP5uuvsLs4yZ8l+bWdHgoAtlt3/8bSMxwJRN0Q3f2QJFl/TMrTutuh1t3jmPUFLgfDfc6OPLYfHAGq6ppJHpDkRkke192fqao7ZnXF+bnLTrczXCgxTFVdLkm6+yvr709M8kNJ3tvdDr8egarqMUm+bQtPOa+7n7Nd87A1th8sr6puk+T1Sc5N8r1Jbtrdf19VT0hyk+6+75Lz7RRRN0xV/XGS13T3s6rqhCTvS3J8khOS/Gh3v3jRAfkGVXXtbG2v+UXd/cntmoetsf1geVX1xiRv7u7Hrz/3/FbrqLtDkt/u7ustPOKOcPh1nn1JHrP++oeTnJ/kBknul9W9tETdkecNSc7Kga9c3qiyOrTgPmdHDtsPlnebrD5NYrOPZ/WZ6HuCqJvnhCT/vP763yb5ve6+pKrekMQhnyPTF7ZyaKCq3rGdw7Blth8s7wu59NMgbprkU5fy+EiXW3oADruPJLljVR2f5LQkr10/frUkn19sKr4Z9znb3Ww/WN6rkjy+qo5df99Vdf0kT0nyO0sNtdNE3TzPSPKbSc5L8tEk+z8W7M5J3rPUUACwjR6d1c6LTye5Yla38Tonyb8k+W8LzrWjHH4dprufV1XvTHLdJK/dfxVskr9L8rjlJgOA7dHd5ye50/rjwk7KaqfVWd39umUn21mibpCqukqSW3b3W5Js/lDjf07y3p2fim3gPme7m+0Hh9HG977ufkNWFy/tX3bHrG7p9dnFBtxBom6WryT546o6rbvfuv/BqrpVVn/Jr7PYZHwzF1fVVu4h+Oltm4RDYfvBsrz3rTmnbpDuviCrk0UfuGnRA5L8SXd/Zuen4iCcm+SiLfz58DJjcgC2HyzIe9/XuPnwMFV1WpLfSnJid1+8/oSJ85I8ort/d9npuDRVdVaS2+fgDstVVjfYdJ+zI4TtB8vz3rfi8Os8r83qfj0/lOR3k5ya5PJJ/mDJofimqrsvPuiVq5yTdWSx/WB53vvi8Os466tdX5Kv7YZ+QJKXd/cly03Ft+A+Z7ub7QcL8963Yk/dTC9O8q6qum6Se2T1fywAMNmef++zp26g7v6bJGcneWmS87r7zIVHAoBt5b3PnrrJXpzkmUkeu/QgfEtXqKpfOMh1nY915LH9drlvsv26u59YVQ9P8u3d/d93ci4OyZ5+73P161BVdbUkP5Xked39iaXn4cCq6s5JrrCFp/xLd799u+Zha2y/3a+qDvQRit3dt6yq1ye5QXffcCfnYuv2+nufqAMAGMA5dQAAA4g6AIABRN1wVXX60jNwaGy73c32291sv91rL287UTffnv3LPYBtt7vZfrub7bd77dltJ+oAAAbY81e/Xr6O7eNy/NJjbJtLclGOybFLj8EhsO12N9tvd7P9dq/p2+6CfPYz3X2NS1u2528+fFyOz8m15z5JBADYhV7Xr/zwgZY5/AoAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMMBhj7qqelNVPftwvy4AAAdmTx0AwACiDgBggC1H3frw6nOr6llV9dn1n1+uqkt9raq6fFU9parOq6rPV9U7quq0DcuPqqrnV9W5VfWFqvpgVT1m4+tV1S2q6vVVdX5VXVhVf1VVd9mw/Huq6tVVdUFVfaqqfquqTtzq7wYAsFsd6p66+62fe4ckP57k9CQ/c4B1X5jkXye5b5KbJ/mNJH9QVbfaMMNHk9wryc2SPDbJzyd5yIbXeFmSjye5XZJbJ3lCki8mSVVdK8mbk5y9Xn7XJCckedWBQhMAYJqjD/F5H0/yyO7uJO+rqpskeVSSZ2xcqapulOQ+Sa7f3R9ZP/zsqrprVjH48O6+JMkvbHjah6rqpPXznr9+7HpJntbd71t/f86G9R+W5K+6+79s+LkPTPJPSfYlOXPz8FV1elYhmuNyxa3+7gAAR5xD3ZP19nXQ7fe2JNepqitvWu+kJJXkvevDphdW1YVJfjDJjfavVFU/UVXvrKpPr5f/5yTX3fA6z0jy61X1hqp6bFXddMOy2yS586bX/4f1shvlUnT3Gd29r7v3HZNjD+HXBwA4shzqnrqDdbkkneS2SS7ZtOwLSVJV907yzCSPTvLnSc5P8pNJ7rF/xe5+QlW9NMndkpyW5PFV9RPd/YL1z3j1+vmbffKw/jYAAEeoQ426k6uqNuytu32Sj3X3+VW1cb13Z7Wn7sTufuMBXutOSf6iu796b7v1Yduv090fTPLBJL9aVf87yX9K8oIkZ2V1Pt6H14dyAQD2nEM9/HrtJM+squ+uqnsm+dkkv7J5pe7+QJKXJnlRVd2zqm5YVfuq6tFV9cPr1T6Q5KSqultV3biqHpfVhRVJkqq6QlU9p6pOqarrV9XJWYXge9erPCfJVZK8vKpOXv+Mu1bVGVV1pUP8/QAAdpVD3VP30iRHJfmLrA6vPj+XEnVrD8nqitanJvnOrC5gODPJ/j13z8vqitaXZbVX73eSPD3JQ9fLv5zk25K8KMm1kvxjkj/M+nBrd3+squ6Y5MlJXpPkuCQfSfKnSS46xN8PAGBXqa+/3uEgnlD1piRnd/cjtmWiHXblulqfXKcuPQYAwLf0un7lu7p736Utcx83AIABRB0AwABbPqeuu0/ZhjkAALgM7KkDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhgbNRV1dlV9YSl5wAA2Aljow4AYC8RdQAAA4g6AIABjl56gCVU1elJTk+S43LFhacBALjs9uSeuu4+o7v3dfe+Y3Ls0uMAAFxmezLqAACmGXv4tbtvvvQMAAA7Zeyeuqp6fVU9Yuk5AAB2wtioS3KjJN++9BAAADth8uHX6y89AwDATpm8pw4AYM8QdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwAC7Juqq6tFV9aGl5wAAOBLtmqgDAODADkvUVdWVq+qqh+O1tvAzr1FVx+3kzwQAOFIdctRV1VFVdVpVvSzJJ5Lcav34VarqjKr6VFVdUFX/r6r2bXjeg6vqwqo6tarOrqrPVdUbq+oGm17/MVX1ifW6L05ywqYR7p7kE+ufdcdD/T0AACbYctRV1fdW1VOT/EOSlyf5XJJ/l+TNVVVJXp3kOkl+KMn3JXlzkjdU1bU2vMyxSX4uyUOT3CHJVZM8d8PPuFeS/5Hk8UlOSvL+JI/aNMpLk9w3yZWSvLaqzqmqX9gchwAAe8FBRV1VXb2qHllV70ry7iQ3TfLTSU7s7h/r7jd3dye5S5JbJ7lnd5/Z3ed09+OS/H2SB2x4yaOT/OR6nb9O8rQkp6yjMEl+JslvdPfzuvsD3f2kJGdunKm7v9Tdf9Td90lyYpJfWv/8D1bVm6rqoVW1ee/e/t/n9Kp6Z1W985JcdDD/CgAAjmgHu6fup5I8K8kXk9yku/9Dd/+f7v7ipvVuk+SKST69Pmx6YVVdmOTmSW60Yb2Luvv9G77/WJLLJ/m29fc3S/K2Ta+9+fuv6u7zu/sF3X2XJLdNcs0kz09yzwOsf0Z37+vufcfk2G/yawMA7A5HH+R6ZyS5JMkDk5xdVb+X5DeTvL67v7xhvcsl+WSSH7iU1zh/w9df2rSsNzx/y6rq2KwO994/q3Pt/iarvX2vOpTXAwDYbQ4qorr7Y939pO7+7iR3TXJhkt9Ocl5VPb2qbr1e9ays9pJ9ZX3odeOfT21hrr9NcvtNj33d97Vyp6p6XlYXavyvJOckuU13n9Tdz+ruz27hZwIA7Fpb3jPW3W/v7ocluVZWh2VvkuQdVfUDSV6X5K1JXlVVd6uqG1TVHarqF9fLD9azkjyoqn6sqm5cVT+X5ORN69w/yZ8muXKS+yT5ru7+2e4+e6u/EwDAbnewh1+/QXdflOSVSV5ZVd+R5Mvd3VV196yuXP21JN+R1eHYtyZ58RZe++VVdcMkT8rqHL3fT/KMJA/esNrrs7pQ4/xvfAUAgL2lVhet7l1Xrqv1yXXq0mMAAHxLr+tXvqu7913aMh8TBgAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwwNFLD7CEqjo9yelJclyuuPA0AACX3Z7cU9fdZ3T3vu7ed0yOXXocAIDLbE9GHQDANKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAxQ3b30DIuqqk8n+fDSc2yjb0/ymaWH4JDYdrub7be72X671/Rtd73uvsalLdjzUTddVb2zu/ctPQdbZ9vtbrbf7mb77V57eds5/AoAMICoAwAYQNTNd8bSA3DIbLvdzfbb3Wy/3WvPbjvn1AEADGBPHQDAAKIOAGAAUQcAMICoAwAYQNQBAAzw/wHpN3LxUDkxAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vKJDCcgo7pKe",
        "outputId": "8defdc17-ccb3-49a0-ffd6-06594fd6e5a9"
      },
      "source": [
        "translate(u'कृपया जाईये।')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> कपया जाईय। <end>\n",
            "Predicted translation: please get us . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw6_lBsX_ff5"
      },
      "source": [
        "Dot Product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBQJb5FQ_e1M"
      },
      "source": [
        "class DotProduct(tf.keras.layers.Layer):\r\n",
        "  def __init__(self,units):\r\n",
        "    super(DotProduct,self).__init__()\r\n",
        "  \r\n",
        "  def call(self, query, values):\r\n",
        "\r\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\r\n",
        "    \r\n",
        "    score  = tf.expand_dims((tf.reduce_sum( tf.multiply(values,query_with_time_axis), 2)),2)\r\n",
        "\r\n",
        "    attention_weights  = tf.nn.softmax(score,axis = 1)\r\n",
        "    \r\n",
        "    context_vector  = attention_weights*values\r\n",
        "    context_vector  = tf.reduce_sum(context_vector , axis=1)\r\n",
        "    \r\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV95EjiFb8vF",
        "outputId": "c80544a7-416d-4c3f-a79d-72a02ca44939"
      },
      "source": [
        "attention_layer = DotProduct(10)\r\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\r\n",
        "\r\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\r\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 29, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_os_8-rcHFe"
      },
      "source": [
        "\r\n",
        "class Decoder(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.dec_units = dec_units\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    # used for attention\r\n",
        "    self.attention = DotProduct(self.dec_units)\r\n",
        "\r\n",
        "  def call(self, x, hidden, enc_output):\r\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\r\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\r\n",
        "\r\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n",
        "    x = self.embedding(x)\r\n",
        "\r\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n",
        "\r\n",
        "    # passing the concatenated vector to the GRU\r\n",
        "    output, state = self.gru(x)\r\n",
        "\r\n",
        "    # output shape == (batch_size * 1, hidden_size)\r\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\r\n",
        "\r\n",
        "    # output shape == (batch_size, vocab)\r\n",
        "    x = self.fc(output)\r\n",
        "\r\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu2BwKVVcVce",
        "outputId": "37885588-71d2-40ab-e695-4733254479b6"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\r\n",
        "                                      sample_hidden, sample_output)\r\n",
        "\r\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 2438)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_pP5TlCdGuV"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "    from_logits=True, reduction='none')\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n",
        "  loss_ = loss_object(real, pred)\r\n",
        "\r\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
        "  loss_ *= mask\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxGTJYuQdGuW"
      },
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/chkpoint_folder/dotproduct'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HggA_tlmdGuW"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(inp, targ, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n",
        "\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "\r\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\r\n",
        "\r\n",
        "    # Teacher forcing - feeding the target as the next input\r\n",
        "    for t in range(1, targ.shape[1]):\r\n",
        "      # passing enc_output to the decoder\r\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n",
        "\r\n",
        "      loss += loss_function(targ[:, t], predictions)\r\n",
        "\r\n",
        "      # using teacher forcing\r\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\r\n",
        "\r\n",
        "  batch_loss = (loss / int(targ.shape[1]))\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "\r\n",
        "  gradients = tape.gradient(loss, variables)\r\n",
        "\r\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\r\n",
        "\r\n",
        "  return batch_loss"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_PSfpB3dGuW",
        "outputId": "6db2de73-ebcf-4df9-fe58-d42bfe991415"
      },
      "source": [
        "EPOCHS = 10\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start = time.time()\r\n",
        "\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\r\n",
        "    total_loss += batch_loss\r\n",
        "\r\n",
        "    if batch % 100 == 0:\r\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                                   batch,\r\n",
        "                                                   batch_loss.numpy()))\r\n",
        "  # saving (checkpoint) the model every 2 epochs\r\n",
        "  if (epoch + 1) % 2 == 0:\r\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                      total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.5136\n",
            "Epoch 1 Loss 1.6961\n",
            "Time taken for 1 epoch 29.96594786643982 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4663\n",
            "Epoch 2 Loss 1.3426\n",
            "Time taken for 1 epoch 5.500558376312256 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1532\n",
            "Epoch 3 Loss 1.1719\n",
            "Time taken for 1 epoch 4.922057628631592 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.0815\n",
            "Epoch 4 Loss 1.0355\n",
            "Time taken for 1 epoch 5.574345350265503 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.8548\n",
            "Epoch 5 Loss 0.9274\n",
            "Time taken for 1 epoch 4.945054769515991 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.8435\n",
            "Epoch 6 Loss 0.8233\n",
            "Time taken for 1 epoch 5.623546600341797 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.7538\n",
            "Epoch 7 Loss 0.7268\n",
            "Time taken for 1 epoch 4.987224340438843 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.5646\n",
            "Epoch 8 Loss 0.6417\n",
            "Time taken for 1 epoch 5.722176551818848 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.5325\n",
            "Epoch 9 Loss 0.5762\n",
            "Time taken for 1 epoch 4.960331201553345 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.4626\n",
            "Epoch 10 Loss 0.4863\n",
            "Time taken for 1 epoch 5.816943645477295 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYNHL2F2dGuW"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\r\n",
        "\r\n",
        "  sentence = preprocess_sentence(sentence)\r\n",
        "\r\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                         maxlen=max_length_inp,\r\n",
        "                                                         padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "\r\n",
        "  result = ''\r\n",
        "\r\n",
        "  hidden = [tf.zeros((1, units))]\r\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "\r\n",
        "  dec_hidden = enc_hidden\r\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\r\n",
        "\r\n",
        "  for t in range(max_length_targ):\r\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "\r\n",
        "    # storing the attention weights to plot later on\r\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "    attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "\r\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\r\n",
        "\r\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\r\n",
        "      return result, sentence, attention_plot\r\n",
        "\r\n",
        "    # the predicted ID is fed back into the model\r\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjecx2sUdGuX"
      },
      "source": [
        "# function for plotting the attention weights\r\n",
        "def plot_attention(attention, sentence, predicted_sentence):\r\n",
        "  fig = plt.figure(figsize=(10,10))\r\n",
        "  ax = fig.add_subplot(1, 1, 1)\r\n",
        "  ax.matshow(attention, cmap='viridis',clim=[0,1])\r\n",
        "\r\n",
        "  fontdict = {'fontsize': 14}\r\n",
        "\r\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\r\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\r\n",
        "\r\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szJJiPH9dGuX"
      },
      "source": [
        "def translate(sentence):\r\n",
        "  result, sentence, attention_plot = evaluate(sentence)\r\n",
        "\r\n",
        "  print('Input: %s' % (sentence))\r\n",
        "  print('Predicted translation: {}'.format(result))\r\n",
        "\r\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\r\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH73jBjkdGuX",
        "outputId": "b63bdcf4-10e5-4a53-e85a-6b0d29afc2aa"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb847991470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9a6sZMpBdGuX",
        "outputId": "d9e91759-5417-4b84-d355-5405e3d15b55"
      },
      "source": [
        "translate(u'बहुत बढ़िया!')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> बहत बढिया ! <end>\n",
            "Predicted translation: happy ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2338 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2338 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lpb82HCSdGuY",
        "outputId": "71dbb929-b677-4882-e17b-99b6e2d7451f"
      },
      "source": [
        "translate(u'कृपया जाईये।')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input: <start> कपया जाईय। <end>\n",
            "Predicted translation: please sit . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2346 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2312 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72xxkA9fdcIe"
      },
      "source": [
        "Do you think that the model attends to the correct tokens in the input language (if you understand both languages)?\r\n",
        "\r\n",
        "For few of them\r\n",
        "\r\n",
        "Do you see qualitative differences in the attention weights between different attention mechanisms?\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG4Ze5_Adrrt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPamtqp5M8Vi"
      },
      "source": [
        "Questions-\r\n",
        "\r\n",
        "Which parts of the sentence are used as a token? Each character, each word, or are some words split up?\r\n",
        "Answer - - Each word\r\n",
        "\r\n",
        "Do the same tokens in different language have the same ID?\r\n",
        "e.g. Would the same token index map to the German word die and to the English word die?\r\n",
        "Answer - No\r\n",
        "\r\n",
        "What is the relation between the encoder output and the encoder hidden state which is used to initialize the decoder hidden state (for the architecture used in the tutorial)?\r\n",
        "Hidden states along with encoder output are used to calculate scores \r\n",
        "\r\n",
        "Is the decoder attending to all previous positions, including the previous decoder predictions?\r\n",
        "Yep\r\n",
        "\r\n",
        "Does the Encoder output change in different decoding steps?\r\n",
        "No\r\n",
        "\r\n",
        "Does the context vector change in different decoding steps?\r\n",
        "yes based on query\r\n",
        "\r\n",
        "The decoder uses teacher forcing. Does this mean the time steps can be computed in parallel?\r\n",
        "Answer - Can be, but predcition word depends on the previous word so might not be a good way\r\n",
        "\r\n",
        "Why is a mask applied to the loss function?\r\n",
        "Answer - because its padded sequence and we don't want loss over padded sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQsNQhe1drQg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}